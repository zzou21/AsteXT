{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program trains a BERT model on 14 stories to identify whether the inputted story is published before or after 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 21:27:14.407966: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json, torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import BertForTokenClassification, TrainingArguments, Trainer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section builds a dataset where the variable \"dataset\" is a list of dictionaries in this format: [{\"story\": storyContent, \"year\": publicationYear, \"label\": 1 for after 2014 and 0 for before 2014}]\n",
    "\n",
    "storyDataJsonPath = \"publicationYearStory.json\"\n",
    "with open(storyDataJsonPath, \"r\") as file:\n",
    "    storyData = json.load(file)\n",
    "dataset = [{\"story\": story, \"year\": int(year)} for year, story in storyData.items()]\n",
    "for story in dataset:\n",
    "    story[\"label\"] = 1 if story[\"year\"] > 2004 else 0\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def tokenizeStories(stories):\n",
    "    return tokenizer(stories[\"story\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "tokenizedStories = [tokenizeStories(storyItem) for storyItem in dataset]\n",
    "#print(tokenizedStories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(tokenizedStories, label):\n",
    "    return{\n",
    "        \"input_ids\": torch.tensor(tokenizedStories[\"input_ids\"]),\n",
    "        \"attentionMask\": torch.tensor(tokenizedStories[\"attention_mask\"]),\n",
    "        \"label\": torch.tensor(label)\n",
    "    }\n",
    "formattedData = [formatData(tokenizedStories[i], dataset[i][\"label\"]) for i in range(len(tokenizedStories))]\n",
    "#print(formattedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [terms[\"label\"] for terms in dataset]\n",
    "trainingData, validationData = train_test_split(formattedData, test_size=0.2, stratify=labels, random_state=2000)\n",
    "#print(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a class for PyTorch (could use another code if one wants to use pyarrow):\n",
    "class StoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data=data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "trainingDataset = StoryDataset(trainingData)\n",
    "validationDataset = StoryDataset(validationData)\n",
    "#print(trainingDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingArgument = TrainingArguments(output_dir=\"./trainingResult\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainingArgument,\n",
    "    train_dataset=trainingDataset,\n",
    "    eval_dataset=validationDataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d98c63cfed4474adbbbeb37ccda74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 176.565, 'train_samples_per_second': 0.17, 'train_steps_per_second': 0.034, 'train_loss': 0.6874442100524902, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36241a000d841ad8e5017a15fe749aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./modelTrained/tokenizer_config.json',\n",
       " './modelTrained/special_tokens_map.json',\n",
       " './modelTrained/vocab.txt',\n",
       " './modelTrained/added_tokens.json',\n",
       " './modelTrained/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()\n",
    "model.save_pretrained('./modelTrained/')\n",
    "tokenizer.save_pretrained(\"./modelTrained/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training ends above. The code below processes the user input data.\n",
    "modelPath = \"modelTrained\"\n",
    "newModel = BertForSequenceClassification.from_pretrained(modelPath)\n",
    "newTokenizer = AutoTokenizer.from_pretrained(modelPath)\n",
    "newModel.eval()\n",
    "\n",
    "def predictInputYear(story, model, tokenizer, threshold=0.5):\n",
    "    inputStory = tokenizer(story, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=256)\n",
    "    operatingDevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # cuda -> gpu\n",
    "    model.to(operatingDevice)\n",
    "    inputStory = {key: value.to(model.device) for key, value in inputStory.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputStory)\n",
    "        logits = outputs.logits\n",
    "    # getting probabilities\n",
    "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "    \n",
    "    # Use 0.5 threshold for binary classification\n",
    "    label = 1 if probabilities[1] > threshold else 0\n",
    "    if label == 1:\n",
    "        return {\"sentiment\": \"After 2014\", \"probability\": probabilities[1]}\n",
    "    else:\n",
    "        return {\"sentiment\": \"Before 2014\", \"probability\": probabilities[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results {'sentiment': 'After 2014', 'probability': 0.6371219}\n"
     ]
    }
   ],
   "source": [
    "newStoryFilePath = \"/Users/Jerry/Desktop/DH proj:reading/Asian American short story project/For testing MrsTsubaki.txt\"\n",
    "with open(newStoryFilePath, \"r\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "storyInput = content\n",
    "resultPrediction = predictInputYear(storyInput, model, tokenizer)\n",
    "print(\"Prediction results\", resultPrediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
